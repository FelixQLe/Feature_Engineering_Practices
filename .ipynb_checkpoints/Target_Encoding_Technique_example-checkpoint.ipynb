{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e087d73d",
   "metadata": {},
   "source": [
    "In this repo, we will apply target encoding technique, is instead a method of encoding categories as numbers, like one-hot or label encoding, with difference  that it also uses the target to create the encoding. This makes it what we call a supervised feature engineering technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c6369c",
   "metadata": {},
   "source": [
    "#### Target Encoding\n",
    "is any kind of encoding that replaces a features's categories with some number derived from the target.\n",
    "\n",
    "* A simple and effective version is to apply a group aggregation from Lesson 3, like the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e0d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>price</th>\n",
       "      <th>make_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>13495</td>\n",
       "      <td>15498.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>16500</td>\n",
       "      <td>15498.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>16500</td>\n",
       "      <td>15498.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audi</td>\n",
       "      <td>13950</td>\n",
       "      <td>17859.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audi</td>\n",
       "      <td>17450</td>\n",
       "      <td>17859.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>audi</td>\n",
       "      <td>15250</td>\n",
       "      <td>17859.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>audi</td>\n",
       "      <td>17710</td>\n",
       "      <td>17859.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>audi</td>\n",
       "      <td>18920</td>\n",
       "      <td>17859.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>audi</td>\n",
       "      <td>23875</td>\n",
       "      <td>17859.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bmw</td>\n",
       "      <td>16430</td>\n",
       "      <td>26118.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          make  price  make_encoded\n",
       "0  alfa-romero  13495  15498.333333\n",
       "1  alfa-romero  16500  15498.333333\n",
       "2  alfa-romero  16500  15498.333333\n",
       "3         audi  13950  17859.166667\n",
       "4         audi  17450  17859.166667\n",
       "5         audi  15250  17859.166667\n",
       "6         audi  17710  17859.166667\n",
       "7         audi  18920  17859.166667\n",
       "8         audi  23875  17859.166667\n",
       "9          bmw  16430  26118.750000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using exmple of Automobiles dataset, compute the average price of each vehicle's make\n",
    "import pandas as pd\n",
    "autos = pd.read_csv('./data/autos.csv')\n",
    "\n",
    "autos['make_encoded'] = autos.groupby('make')['price'].transform('mean')\n",
    "\n",
    "autos[['make', 'price', 'make_encoded']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bec53",
   "metadata": {},
   "source": [
    "This technique sometimes called a mean encoding. Applied to a binary target, it's also called bin counting, likelihood encoding, impact encoding, and leave one out encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec026c",
   "metadata": {},
   "source": [
    "#### Smoothing\n",
    "An encoding like this presents a couple of problems, however. \n",
    "\n",
    "- First are unknown categories. Target encodings create a special risk of overfitting, which means they need to be trained on an independent 'encoding' split. When we join  the encoding to future splits, Pandas will fill in missing values for any categories not present in the encoding split. These missing values we would have to impute somehow.\n",
    "\n",
    "- Second are rare categories. When a category only occurs a few times in the dataset, any statisics calculated on its group are unlikely to be very accurate. In the Automobiles dataset, the mercurcy make only occurs once. The 'mean' price we calculated is just the price of that one vehicle, which might not be very representative of any Mercuries we might see in the future. Target encoding rare categories can make overfitting more likely.\n",
    "\n",
    "A solution to these problems is to add smoothing. The idea is to blend the in_category average with the overall average. Rare categories get less weight on their category average, while missing categories just get the overall average.\n",
    "\n",
    "In pseudocode:\n",
    "encoding = weight * in_category + (1- weight) * overall\n",
    "\n",
    "Where weight is a value between 0 and 1 calculated from the category frequency\n",
    "\n",
    "An easy way to determine the value for weight is to compute an m-estimate:\n",
    "weight = n / (n+m)\n",
    "\n",
    "where n is the total number of times that category occurs in the data. The parameter m determines the 'smoothing factor'. Larger values of m put more weight on the overall estimate.\n",
    "\n",
    "<img src=\"https://i.imgur.com/1uVtQEz.png\">\n",
    "\n",
    "In the Automobiles dataset there are three cars with the make chevrolet. If we chose m=2.0, then the chevrolet category would be encoded with 60% of the average Chevrolet price plus 40$ of the overall average price\n",
    "\n",
    "chevrolet = 0.6 * 6000.00 + 0.4 * 13285.03\n",
    "\n",
    "When choosing a value for m, consider how noisy we expect the categories to be. Does the price of a vehicle vary a greate deal within each make? Would we need a lot of data to get good estimates? If so, it could be better to choose a larger value for m, If the average price for each make were relatively stable, a smaller value could be okay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f099a8cf",
   "metadata": {},
   "source": [
    "#### Use Cases for Target Encoding\n",
    "Great for:\n",
    "* High-cardinality features: A feature with a large number of categories can be troublesome to encode: a one-hot encoding would generate too many features and alternatives, like a label encoding, might not be appropriate for that feature. A target encoding derives numbes for the categories using the feature's most important property: its relationship with the target.\n",
    "* Domain-motivated features: From prior experience, you might suspect that a categorical feature should be important even if it scored poorly with a feature metric. A target encoding can help reaveal a feature's true informativeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e9db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro_project",
   "language": "python",
   "name": "pro_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
